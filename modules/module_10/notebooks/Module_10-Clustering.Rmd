---
title: "Module 10 - Hierarchical & k-means clustering"
author: "Loyal Goff"
date: "2022-11-06"
output:
  html_document:
    toc: true
    toc_level: 3
    toc_float: true
    theme: yeti
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Import
```{r}
library(SummarizedExperiment)
library(tidyverse)

# Read in the data
data <- read.csv("https://github.com/gofflab/Quant_mol_neuro_2022/raw/main/modules/module_9/notebooks/GSE63482_Expression_matrix.tsv", sep = " ", header = T, row.names = 1)
```

```{r}
# Parse header into parameters
sample_metadata <- as.data.frame(stringr::str_split_fixed(colnames(data), "_", 2))
colnames(sample_metadata) <- c("Age", "CellType")
sample_metadata$SampleID <- colnames(data)
colData <- DataFrame(sample_metadata)

# Create Gene metadata
gene_metadata <- data.frame(geneName = rownames(data))
rownames(gene_metadata) <- rownames(data)
gene_metadata <- DataFrame(gene_metadata)

# Create a Summarized Experiment object
se <- SummarizedExperiment(
  assays = SimpleList(fpkm = as.matrix(data)),
  rowData = gene_metadata,
  colData = sample_metadata
)
assay(se,'logfpkm')<-log10(assay(se,'fpkm')+1)
```

# Clean/process data to cluster
```{r}
clustData<-assay(se,'logfpkm')
clustData<-clustData[rowMeans(clustData)>=1,]
```

# Hierarchical clustering
First we will need to compute a distance matrix of the pairwise distances across samples. To do this we will use the `dist()` function. `dist()` operates over rows, so if we want to calculate the distance between samples, we will have to transpose (`t()`) clustData.
```{r}
clustData.dist<-dist(t(clustData))
clustData.dist
```

```{r}
hclust(clustData.dist)

plot(hclust(clustData.dist),main="Euclidean:complete")
```


```{r}
clustData.dist<-dist(t(clustData),method="manhattan")

plot(hclust(clustData.dist),main="Manhattan:complete")
```

Partition by choosing k
```{r}
clustData.hclust<-hclust(clustData.dist)
plot(clustData.hclust)
clus3<-cutree(clustData.hclust,k=3)
clus3

```

Partition by fixing height
```{r}
clustData.hclust<-hclust(clustData.dist)
plot(clustData.hclust)
height<-1000
abline(h=height,lty="dashed",col="red")
clusH1000<-cutree(clustData.hclust,h=height)
clusH1000

```

# K-means
Let's try and identify groups of genes that behave similarly across the conditions. To do this, and to avoid the complication of absolute expression level (we're interested in 'patterns' across conditions), we will first center & scale the row(gene) data.
```{r}
nClusters<-12
clustData.scaled<-t(scale(t(clustData)))
clustData.kmeans<-kmeans(clustData.scaled,nClusters)
```

```{r}
clustData.plot<-clustData.scaled
clustData.plot<-as.data.frame(clustData.plot)
clustData.plot$gene<-rownames(clustData.plot)
clustData.plot$cluster<-clustData.kmeans$cluster
clustData.melt<-reshape2::melt(clustData.plot,id.vars=c("gene","cluster"))
clustData.melt<-merge(clustData.melt,colData(se),by.x="variable",by.y="SampleID")
clustData.melt<-as.data.frame(clustData.melt)
```

Summarise data across clusters with dplyr
```{r}
kmeans.summary <- clustData.melt %>%
  group_by(cluster,Age,CellType) %>%
  summarise(mean=mean(value),sd=sd(value))
```

```{r}
p<-ggplot(kmeans.summary,aes(x=Age,
                             y=mean,
                             ymax=mean+sd,
                             ymin=mean-sd
                             )) + 
  geom_point(aes(color=CellType)) +
  geom_line(aes(group=CellType,color=CellType)) +
  geom_hline(yintercept=0,linetype="dashed") + 
  #geom_ribbon(aes(group=CellType,color=CellType,fill=CellType),alpha = 0.2)
  theme_minimal()
p + facet_wrap('cluster',scales="free_y")
```

# Clustering QC

## Choosing a k
### Elbow method
A naive approach to determining the choice of k by minimizing the 'Within-cluster-sum of Squared Errors' (WSS) across different choices of k. The WSS is the sum of the distances for each point to its cluster centroid. This is conveniently calculated for us and provided for each kmeans result in the `$tot.withinss` slot.

```{r}
clustData.kmeans$tot.withinss
```

Since we're interested in minimizing this across different values of k to choose an optimal k, let's write a for loop to do this for us.

```{r}
kRange<-c(2:30)
wss<-c()
for (i in kRange){
  print(i)
  clust<-kmeans(clustData.scaled,i,iter.max = 100)
  wss<-c(wss,clust$tot.withinss)
}
```

Now that we have performed the clustering over a range of k-values, let's plot the wss trends and see where the elbow of the curve is located. We want to choose a k that minimizes the wss, but doesn't 'overfit' the data.

```{r}
plot(kRange,wss,type="l")
```

### Silhouette method

Silhouette Score = (b-a)/max(a,b)
where:
  - a = average intra-cluster distance i.e the average distance between each point within a cluster.
  - b = average inter-cluster distance i.e the average distance between all clusters.

```{r}
library(cluster)
D<-dist(clustData.scaled)
kmeans.sil<-silhouette(clustData.kmeans$cluster,D)
plot(kmeans.sil,border=NA,col=1:12)

silhouette_score <- function(k){
  km <- kmeans(clustData.scaled, centers = k, iter.max=100)
  ss <- silhouette(km$cluster, dist(clustData.scaled))
  mean(ss[, 3])
}

kRange <- c(2:30)
avg_sil <- lapply(kRange, silhouette_score)
plot(kRange, type='b', avg_sil, xlab='Number of clusters', ylab='Average Silhouette Scores', frame=FALSE)


nClusters<-12
clustData.kmeans<-kmeans(clustData.scaled,nClusters,iter.max=100)
kmeans.sil<-silhouette(clustData.kmeans$cluster,D)
plot(kmeans.sil,border=NA,col=1:nClusters)

```

## UMAP on genes to visualize cluster relationships
```{r}
library(uwot)
genes.umap<-uwot::umap(clustData.scaled,verbose=T) # or uwot::umap()
plot(genes.umap,
     col=clustData.kmeans$cluster,
     pch=20) #Run this several times....
```


# Session Information
```{r}
sessionInfo()
```

